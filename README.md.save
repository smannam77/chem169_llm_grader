
# GraderBot Chem 169o00


LLM-powered grading assistant for Jupyter notebooks. Designed for Chem 169/269 "routes" but adaptable to other courses.

## Features

- Parse assignment specifications ("routes") from Markdown files
- Convert Jupyter notebooks to a compact grading view
- Grade student work using LLM APIs (OpenAI-compatible or Anthropic)
- Produce structured JSON output with evidence-based grading
- Three-level rating system: EXCELLENT, OK, NEEDS_WORK
- Automatic JSON validation and repair
- Dry-run mode for prompt inspection

## Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or install in development mode
pip install -e .
```

## Quick Start

### 1. Set up API credentials

Create a `.env` file in the project root:

```bash
# For OpenAI
OPENAI_API_KEY=sk-...

# For Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-...
```

### 2. Grade a notebook

```bash
# Basic usage with OpenAI
graderbot grade --route examples/route.md --notebook examples/student_submission.ipynb --out result.json

# Use Anthropic/Claude
graderbot grade --route examples/route.md --notebook examples/student_submission.ipynb --provider anthropic

# Dry run (see prompts without calling API)
graderbot grade --route examples/route.md --notebook examples/student_submission.ipynb --dry-run

# Output to stdout
graderbot grade --route examples/route.md --notebook examples/student_submission.ipynb
```

### 3. Utility commands

```bash
# Parse and inspect a route file
graderbot parse-route examples/route.md

# View notebook in grading format
graderbot view-notebook examples/student_submission.ipynb
```

## CLI Reference

```
graderbot grade [OPTIONS]

Options:
  -r, --route PATH        Path to the route/assignment markdown file [required]
  -n, --notebook PATH     Path to the student Jupyter notebook [required]
  -o, --out PATH          Path to write grading JSON output (default: stdout)
  -p, --provider TEXT     LLM provider: openai, anthropic, or mock [default: openai]
  -m, --model TEXT        Model to use (provider-specific default if not set)
  --route-id TEXT         Route/assignment identifier to include in output
  --student-id TEXT       Student identifier to include in output
  -d, --dry-run           Print composed prompt without calling LLM API
  --max-retries INTEGER   Maximum retries for JSON repair [default: 2]
  -v, --version           Show version and exit
```

## Output Schema

```json
{
  "schema_version": "1.0",
  "route_id": "string or null",
  "student_id": "string or null",
  "exercises": [
    {
      "exercise_id": "Exercise 1",
      "rating": "EXCELLENT | OK | NEEDS_WORK",
      "rationale": "Brief explanation (max 3 sentences)",
      "evidence": [
        {"cell_index": 0, "excerpt": "relevant code or output"}
      ],
      "missing_or_wrong": ["list of specific issues"],
      "flags": ["not_executed", "incomplete", etc.]
    }
  ],
  "overall_summary": "Overall assessment (max 5 sentences)"
}
```

## Grading Rubric

| Rating | Description |
|--------|-------------|
| **EXCELLENT** | Correct, clear, and reproducible. Fully addresses the prompt. |
| **OK** | Mostly correct but incomplete/sloppy. Minor bugs or weak explanation. |
| **NEEDS_WORK** | Incorrect, missing, or doesn't address prompt. Evidence of not running or copy/paste. |

## Route File Format

Routes are Markdown files with exercise headings:

```markdown
# Assignment Title

Optional preamble with instructions.

## Exercise 1: Title

Instructions for exercise 1...

## Exercise 2

Instructions for exercise 2...

## Exercise 3a

Sub-exercise instructions...
```

## Project Structure

```
graderbot/
├── __init__.py         # Package init with version
├── cli.py              # Typer CLI application
├── route_parser.py     # Markdown route parsing
├── notebook_view.py    # Notebook to grading view conversion
├── llm_client.py       # Pluggable LLM clients
├── schema.py           # Pydantic models
├── prompts.py          # System and user prompt templates
└── grader.py           # Main grading orchestration

tests/                  # Unit tests
examples/               # Sample route and notebook
```

## Requirements

- Python 3.11+
- pydantic
- nbformat
- typer
- python-dotenv
- httpx

## Running Tests

```bash
pytest tests/ -v
```

## Development

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests with coverage
pytest tests/ -v --cov=graderbot

# Type checking
mypy graderbot/
```

## License

MIT
>>>>>>> c7447a0 (Initial commit)
